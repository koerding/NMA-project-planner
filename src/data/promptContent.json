{
  "researchApproaches": {
    "context": "IMPORTANT CONTEXT ABOUT RESEARCH APPROACHES:\n\nThere are fundamentally different types of research questions that require different approaches:\n\n1. HYPOTHESIS-DRIVEN RESEARCH:\n   - Tests competing explanations about how the world works\n   - Structure: \"Is the world more like A or more like B?\"\n   - Example: \"Does increased screen time (A) or reduced physical activity (B) contribute more to childhood obesity?\"\n   - Scientific value comes from distinguishing between plausible alternative explanations\n   - Common in basic sciences (biology, psychology, neuroscience)\n   - Success means advancing theoretical understanding, even if no immediate application\n\n2. NEEDS-BASED RESEARCH:\n   - Addresses a specific problem that someone needs solved\n   - Structure: \"How can we create X to solve problem Y for stakeholder Z?\"\n   - Example: \"How can we develop a screening tool to help doctors identify infants at risk for cerebral palsy?\"\n   - Value comes from solving a real-world problem for specific stakeholders\n   - Common in applied fields (medicine, engineering, design)\n   - Success means creating something useful, even if it doesn't test fundamental theories\n\n3. EXPLORATORY RESEARCH:\n   - Examines data/phenomena without predetermined hypotheses to discover patterns\n   - Structure: \"What patterns exist in X that we haven't noticed before?\"\n   - Example: \"What patterns of gene expression emerge when examining cancer cells under different conditions?\"\n   - Value comes from discovering unexpected relationships\n   - Used in emerging fields or for complex systems\n   - Success means identifying novel patterns worthy of further investigation",
    "questions": {
      "hypothesis": [
        "What are the two competing explanations your research is trying to distinguish between?",
        "How would the world look different if hypothesis A is true versus if hypothesis B is true?",
        "What key evidence would allow you to determine whether hypothesis A or B is more likely correct?",
        "What would be the theoretical significance if your first hypothesis turns out to be supported?",
        "How do your competing hypotheses relate to existing theories in the field?",
        "What prediction does each of your hypotheses make that the other doesn't?",
        "How will you know if neither of your hypotheses adequately explains what you observe?",
        "What makes distinguishing between these particular hypotheses scientifically interesting?"
      ],
      "needsresearch": [
        "Who specifically will benefit from your solution and what problem does it solve for them?",
        "How do the stakeholders currently address this need without your solution?",
        "What metrics will you use to determine if your solution is actually solving the problem?",
        "What are the limitations of existing approaches that make your solution necessary?",
        "How have you validated that this is actually a problem worth solving?",
        "What would constitute 'success' for your solution from the stakeholders' perspective?",
        "What constraints (ethical, technical, economic) are you working within?",
        "How will you measure improvement over current approaches?"
      ],
      "exploratory": [
        "What patterns or relationships are you hoping to discover in your data?",
        "How will you distinguish meaningful patterns from random noise?",
        "What makes this particular exploration valuable to your field?",
        "What would be a surprising finding that could emerge from this exploration?",
        "How open-ended is your exploration and how will you determine when to focus on specific patterns?",
        "What analytical approaches will help you discover unexpected patterns?",
        "How will you validate whether the patterns you find are meaningful?",
        "What might you discover that would warrant a shift to hypothesis-testing in future work?"
      ],
      "general": [
        "What aspects of this topic do you find most interesting?",
        "What questions do you have about this section?",
        "What's the most challenging part of this section for you?",
        "How does this connect to your overall research goals?",
        "What progress have you made so far in this area?",
        "What would make this section stronger in your view?",
        "What feedback have you received from others about this part?",
        "How might someone critique this aspect of your research?"
      ]
    },
    "approachGuidance": {
      "hypothesis": "focus on helping them articulate clear, competing explanations",
      "needsresearch": "focus on helping them clarify the stakeholder, problem, and proposed solution",
      "exploratory": "focus on helping them articulate patterns they hope to discover"
    }
  },
  "systemPrompts": {
    "chat": "You are a young, helpful professor with minimal ego. You guide students EXCLUSIVELY by asking thoughtful questions rather than providing direct answers - this is the only way you communicate.\n\nYour approach:\n- Ask open-ended questions that spark critical thinking\n- NEVER lecture or give direct instructions - only ask questions\n- Respond to student input with follow-up questions that deepen their thinking\n- Maintain a casual, friendly tone with occasional humor\n- Express genuine curiosity about their ideas\n- Use questions to gently challenge assumptions\n- Keep responses concise and focused on guiding their thinking\n- When asked direct questions, respond with questions that help them find their own answer\n\n{{researchApproachContext}}\n\nThe student is working on a scientific paper plan, specifically the \"{{sectionTitle}}\" section.\n\n{{approachGuidance}}\n\nSection instructions: {{instructionsText}}\n\nRelated feedback (if any): {{feedbackText}}\n\nStudent's current work: {{userContent}}",
    "documentImport": "You are analyzing a scientific paper to extract its structure. Be methodical and accurate.\n\n{{researchApproachContext}}\n\nPay particular attention to whether this is a hypothesis-driven, needs-based, or exploratory research paper. Look for these indicators:\n- Hypothesis-driven papers test competing explanations (A vs B)\n- Needs-based papers solve problems for stakeholders\n- Exploratory papers discover patterns without predetermined hypotheses\n\nLook for the structure of the research question and how results are valued to determine the approach.\n\nDocument text (first part): {{documentTextSnippet}}",
    "instructionImprovement": "You are providing feedback on a student's scientific paper plan, with expertise in formatting precise, valid JSON.\n\n{{researchApproachContext}}\n\nYour response MUST be a properly formatted JSON array with objects for each section. Each object must contain:\n- 'id': The section ID (string)\n- 'editedInstructions': Edited instructions text (string)\n- 'feedback': Your feedback on their work (string)\n- 'completionStatus': ONLY use \"complete\" or \"unstarted\" (string)\n\nBe VERY lenient with the completionStatus. If the student has written anything at all beyond the template, mark it as \"complete\" - only use \"unstarted\" if the section is empty or unchanged from the template.\n\nAvoid any formatting issues in your JSON. Make sure all strings use proper escape sequences (\\n for newlines, \\\" for quotes) and the array is valid JSON that can be parsed directly.\n\nWhen analyzing sections, determine which research approach they're using (hypothesis-driven, needs-based, or exploratory) and tailor your feedback accordingly.\n\n{{approachGuidance}}"
  },
  "taskPrompts": {
    "documentImport": "# Scientific Paper Extraction - Strict Format\n\n## Task Overview\nExtract key components from the provided scientific paper text and format them in a JSON structure that can be loaded by the Scientific Paper Planner tool. The provided text was automatically extracted and may contain formatting errors or be truncated.\n\n## CRITICAL JSON FORMATTING REQUIREMENTS\n1. Use ONLY plain ASCII characters.\n2. Do NOT use any HTML tags.\n3. Keep content simple and straightforward.\n4. Replace mathematical variables with text descriptions.\n5. Use only single quotes for nested strings if needed.\n6. Use standard newlines only.\n7. Ensure JSON remains valid.\n\n## Research Approach Selection\nDetermine which research approach the paper likely uses based *only* on the provided text:\n1. Hypothesis-driven (distinguish between hypotheses)\n2. Needs-based (solve a problem, e.g. engineering or medicine)\n3. Exploratory (take data and see what is there)\n\n## Data Collection Method Selection\nDetermine which data collection method the paper likely uses based *only* on the provided text:\n1. Experiment\n2. Analysis of Existing Data\n\n## Output Format\nOutput valid JSON matching this exact structure:\n{\n  \"userInputs\": {\n    \"question\": \"Research Question: [simple description based on text]\\n\\nSignificance/Impact: [simple description based on text]\",\n    \"audience\": \"Target Audience/Community (research fields/disciplines):\\n1. [audience1 based on text]\\n2. [audience2 based on text]\\n3. [audience3 based on text]\\n\\nSpecific Researchers/Labs (individual scientists or groups):\\n1. [researcher1 based on text]\\n2. [researcher2 based on text]\\n3. [researcher1 based on text]\",\n\n    // CHOOSE ONE based on text:\n    \"hypothesis\": \"Hypothesis 1: [simple description based on text, only mention lack of clarity if it is truly unclear]\\n\\nHypothesis 2: [simple description based on text, only mention lack of clarity if it is truly unclear]\\n\\nWhy distinguishing these hypotheses matters:\\n- [reason1 based on text]\\n- [reason2 based on text]\",\n    \"needsresearch\": \"Who needs this research:\\n[stakeholders based on text]\\n\\nWhy they need it:\\n[problem description based on text]\\n\\nCurrent approaches and limitations:\\n[existing solutions based on text]\\n\\nSuccess criteria:\\n[evaluation methods based on text]\\n\\nAdvantages of this approach:\\n[benefits based on text]\",\n    \"exploratoryresearch\": \"Phenomena explored:\\n[description based on text]\\n\\nPotential discoveries your approach might reveal:\\n1. [finding1 based on text, if unspecified mention]\\n2. [finding2 based on text, if unspecified mention]\\n\\nValue of this exploration to the field:\\n[importance based on text, mention if there is lack of clarity]\\n\\nAnalytical approaches for discovery:\\n[methods based on text]\\n\\nStrategy for validating findings:\\n[validation based on text]\",\n\n    \"relatedpapers\": \"Most similar papers that test related hypotheses:\\n1. [paper1 based on text, ideally give full reference]\\n2. [paper2 based on text, ideally give full reference]\\n3. [paper3 based on text, ideally give full reference]\\n4. [paper4 based on text, ideally give full reference]\\n5. [paper5 based on text, ideally give full reference]\",\n\n    // CHOOSE ONE based on text:\n    \"experiment\": \"Key Variables:\\n- Independent: [variables based on text, mention if the text does not mention any]\\n- Dependent: [variables based on text, mention if the text does not mention any]\\n- Controlled: [variables based on text, mention if the text does not mention any]\\n\\nSample & Size Justification: [simple description based on text, mention if the text does not mention any]\\n\\nData Collection Methods: [simple description based on text, mention if the text does not mention any]\\n\\nPredicted Results: [simple description based on text, mention if the text does not mention any]\\n\\nPotential Confounds & Mitigations: [simple description based on text, mention if the text does not mention any]\",\n    \"existingdata\": \"Dataset name and source:\\n[description based on text, mention if the text does not specify]\\n\\nOriginal purpose of data collection:\\n[description based on text, mention if text does not specify]\\n\\nRights/permissions to use the data:\\n[description based on text, mention if the text does not specify]\\n\\nData provenance and quality information:\\n[description based on text, mention if the text does not specify]\\n\\nRelevant variables in the dataset:\\n[description based on text, mention if the text does not specify]\\n\\nPotential limitations of using this dataset:\\n[description based on text, mention if not specified]\",\n\n    \"analysis\": \"Data Cleaning & Exclusions:\\n[simple description based on text, mention if the text does not specify]\\n\\nPrimary Analysis Method:\\n[simple description based on text]\\n\\nHow Analysis Addresses Research Question:\\n[simple description based on text, mention if this is not clear]\\n\\nUncertainty Quantification:\\n[simple description based on text, this includes any statistical method, mention if not specified]\\n\\nSpecial Cases Handling:\\n[simple description based on text]\",\n    \"process\": \"Skills Needed vs. Skills I Have:\\n[simple description based on text, guess where necessary]\\n\\nCollaborators & Their Roles:\\n[simple description based on text, guess where necessary]\\n\\nData/Code Sharing Plan:\\n[simple description based on text]\\n\\nTimeline & Milestones:\\n[simple description based on text]\\n\\nObstacles & Contingencies:\\n[simple description based on text, guess where necessary]\",\n    \"abstract\": \"Background: [simple description based on text]\\n\\nObjective/Question: [simple description based on text]\\n\\nMethods: [simple description based on text]\\n\\n(Expected) Results: [simple description based on text]\\n\\nConclusion/Implications: [simple description based on text]\"\n  },\n  \"chatMessages\": {},\n  \"timestamp\": \"{{isoTimestamp}}\",\n  \"version\": \"1.0-text-extraction\"\n}\n\n## IMPORTANT:\n- Base extraction *solely* on the provided text, which might be messy or truncated.\n- If information for a field is not found, explicitly state 'Not found in text'.\n- If educated guesses are needed, make sure to communicate the lack of clarity.\n- Include ONLY ONE research approach field.\n- Include ONLY ONE data collection field.\n- Adhere STRICTLY to all JSON formatting rules.\n\nBased *only* on the text provided below, create the scientific paper structure in the specified JSON format.\n\n--- DOCUMENT TEXT START ---\n{{documentText}}\n--- DOCUMENT TEXT END ---",
    "instructionImprovement": "I need you to improve instructions and provide feedback for some sections of a scientific paper planner.\n\nFor each section, I'll provide:\n- Section ID and title\n- Original instructions text\n- User's current content\n\nFor EACH section, please provide:\n1. Edited Instructions: Remove points the user has already addressed. If they've addressed all key points, provide a congratulatory message.\n2. Feedback: Brief, constructive feedback noting strengths, weaknesses, and suggestions.\n3. Completion Status: ONLY use \"complete\" or \"unstarted\" as values, where:\n   - \"complete\" = The student wouldn't be embarrassed to show this to their professor (be VERY lenient here)\n   - \"unstarted\" = The section is essentially empty or unchanged from the template\n\nCRITICAL: Format your response as a valid JSON array of objects. Each object MUST have these exact keys:\n- \"id\": The section ID (string)\n- \"editedInstructions\": The edited instructions or congratulatory message (string)\n- \"feedback\": The feedback (string)\n- \"completionStatus\": ONLY \"complete\" or \"unstarted\" (string)\n\nHere are the sections to improve:\n{{sectionsData}}\n\nIMPORTANT:\n- Use a VERY lenient standard for marking as \"complete\" - if the student has written anything meaningful at all, mark it as \"complete\"\n- Structure your response as clean, parseable JSON\n- DO NOT prefix your response with \"code blocks\" or add any markdown formatting\n- Start with \"[\" and end with \"]\"\n- Use proper JSON escaping for newlines (\\n) and quotes"
  },
  "mockResponses": {
    "chat": {
      "hypothesis": "Hey there! Let's explore your competing explanations together. I'm curious - how might you test whether {{hypothesis_aspect}} is the key factor compared to {{alternative_aspect}}? What prediction does each hypothesis make that the other doesn't?",
      "needsresearch": "That's an interesting point about the problem you're solving. I wonder - considering the needs of {{stakeholder}}, what would be the most critical feature for them in a solution like the one you're proposing? How would you measure success from their perspective?",
      "exploratory": "Fascinating pattern you're exploring! What other related variables could you examine to see if this connection holds true under different conditions? How will you distinguish meaningful patterns from random noise?",
      "general": "That's a thoughtful way to put it. What assumptions are underlying your approach, and how could you verify them? What aspect of this topic do you find most challenging?"
    },
    "instructionImprovement": "[{\"id\":\"question\",\"editedInstructions\":\"Great job defining your research question! You're asking whether speed-dating events between scientists increase collaboration probability, which is clear and testable. Here are some additional points to consider: 1) Think about the scope - are you focusing on specific scientific disciplines? 2) Consider quantifying what 'increased collaboration' means (joint papers, grant applications, etc.).\",\"feedback\":\"**Strengths:** Clear question.\\n**Weaknesses:** Scope unclear.\\n**Suggestions:** Define collaboration metrics.\",\"completionStatus\":\"complete\"},{\"id\":\"hypothesis\",\"editedInstructions\":\"Excellent work! You've addressed all key points. Ready for the next step!\",\"feedback\":\"**Strengths:** Both hypotheses are clear and testable.\\n**Weaknesses:** None noted.\\n**Suggestions:** Proceed to experiment design.\",\"completionStatus\":\"complete\"}]",
    "documentImport": "{\"userInputs\":{\"question\":\"Research Question: How do speed-dating events between scientists from different disciplines affect collaboration rates?\\n\\nSignificance/Impact: Understanding factors that promote interdisciplinary collaboration could lead to more innovative research.\",\"audience\":\"Target Audience/Community (research fields/disciplines):\\n1. Science of Team Science researchers\\n2. Research policy makers\\n3. University administrators\\n\\nSpecific Researchers/Labs (individual scientists or groups):\\n1. Northwestern CTSA team science group\\n2. SciTS conference attendees\\n3. University research offices\",\"hypothesis\":\"Hypothesis 1: Scientists who participate in structured speed-dating events will form more interdisciplinary collaborations than those who attend traditional networking events.\\n\\nHypothesis 2: The formation of new collaborations will depend more on complementary skills than on personal rapport.\\n\\nWhy distinguishing these hypotheses matters:\\n- Would inform design of effective scientific networking events\\n- Could challenge assumptions about how scientific collaborations form\",\"relatedpapers\":\"Most similar papers that test related hypotheses:\\n1. Smith et al. (2018) 'Network formation in scientific conferences'\\n2. Jones & Lee (2019) 'Interdisciplinary collaboration patterns in STEM fields'\\n3. Zhang et al. (2020) 'Speed-networking in academic medical centers'\\n4. Williams (2017) 'Factors influencing research collaboration formation'\\n5. Brown et al. (2021) 'Measuring outcomes of structured networking events'\",\"experiment\":\"Key Variables:\\n- Independent: Event type (speed-dating vs traditional networking)\\n- Dependent: Number of new collaborations formed, interdisciplinarity of collaborations\\n- Controlled: Academic rank, prior collaboration history\\n\\nSample & Size Justification: 200 scientists from diverse disciplines, power analysis indicates 80% power to detect 20% difference\\n\\nData Collection Methods: Pre-event surveys, post-event tracking of collaboration outcomes for 12 months\\n\\nPredicted Results: Speed-dating group will show 30% more interdisciplinary collaborations\\n\\nPotential Confounds & Mitigations: Self-selection bias mitigated by random assignment where possible\",\"analysis\":\"Data Cleaning & Exclusions:\\nParticipants who don't complete follow-up surveys will be excluded from final analysis\\n\\nPrimary Analysis Method:\\nPoisson regression for collaboration count data, controlling for academic rank and prior collaboration history\\n\\nHow Analysis Addresses Research Question:\\nWill directly compare collaboration rates between conditions while accounting for important covariates\\n\\nUncertainty Quantification:\\nBootstrap confidence intervals for all estimates, sensitivity analysis for missing data\\n\\nSpecial Cases Handling:\\nOutliers (>3 SD from mean) will be analyzed separately\",\"abstract\":\"Background: Interdisciplinary collaboration drives scientific innovation, but little is known about how to effectively foster such collaborations.\\n\\nObjective/Question: This study examines whether structured speed-dating events between scientists from different disciplines lead to more interdisciplinary collaborations compared to traditional networking events.\\n\\nMethods: 200 scientists will be randomly assigned to either speed-dating or traditional networking events, with collaboration outcomes tracked for 12 months.\\n\\n(Expected) Results: We expect speed-dating events to yield 30% more interdisciplinary collaborations, with collaboration quality dependent on skill complementarity rather than personal rapport.\\n\\nConclusion/Implications: Findings will inform the design of scientific networking events and advance understanding of collaboration formation mechanisms.\"},\"chatMessages\":{},\"timestamp\":\"2023-04-05T15:30:00.000Z\",\"version\":\"1.0-text-extraction\"}"
  }
}

{
  "title": "Scientific Paper Planner Sections",
  "sections": [
    {
      "id": "question",
      "title": "Research Question & Philosophy",
      "type": "text",
      "maxLength": 3000,
      "inputPlaceholder": "Start writing your research question and philosophy here...",
      "completeButtonText": "MARK COMPLETE",
      "loadingButtonText": "Processing...",
      "instructions": {
        "title": "Formulating Your Research Question & Philosophy",
        "text": "A **clear, meaningful, and answerable research question** is the foundation of your study. It drives understanding and innovation.\n\n### Key Steps:\n\n1.  **Define Your Research Philosophy:** This is crucial as it shapes your entire approach. Choose the primary logic for your study:\n    * **Hypothesis Testing:** Does mechanism X explain observation Y? Can I distinguish between competing explanations?\n    * **Exploratory:** What patterns exist? What relationships can be found? What areas are active?\n    * **Needs-Driven/Engineering:** How can I solve problem X? What intervention achieves outcome Y?\n    * *Action:* Explicitly state your chosen philosophy and justify why it fits your goals.\n\n2.  **Formulate the Research Question:**\n    * **Clarity & Specificity:** Be precise about what you want to study. Define key terms.\n    * **Scope:** Ensure the question is narrow enough to be answerable with your anticipated resources and time.\n    * **Significance:** Explain why the question matters *to the field* and what its objectives are.\n    * **Audience:** Identify the community or stakeholders who would be interested in the answer.\n    * *Action:* Draft your question, incorporating these elements.\n\n3.  **Ensure Alignment:** Verify that your research question is compatible with your chosen research philosophy. For example, a hypothesis-testing question needs competing explanations; an exploratory question focuses on discovery.\n\n4.  **Refine:** Plan to revisit and refine your question and philosophy as your understanding evolves during the planning process."
      },
      "placeholder": "Research Question:[Write it out] \n\nSignificance/Impact: [Why it matters]\n\n Logic:[Hypothesis test/Measurement/Filling a need] \n\n Target Audience/Community:\n1. \n2. \n3. \n4. \n5. ",
      "placeholders": {
        "hypothesis": "Research Question:\n\nResearch Philosophy: [I am taking a hypothesis-testing approach because...]\n\nSignificance/Impact:\n- \n- \n- \n\nKey Terms Defined:\n- Term 1: Definition\n- Term 2: Definition\n\nTarget Audience/Community:\n1. \n2. \n3. \n4. \n5. ",
        "exploratory": "Research Area for Exploration:\n\nResearch Philosophy: [I am taking an exploratory approach because...]\n\nSignificance/Impact:\n- \n- \n- \n\nKey Terms Defined:\n- Term 1: Definition\n- Term 2: Definition\n\nTarget Audience/Community:\n1. \n2. \n3. \n4. \n5. ",
        "needs": "Problem Statement:\n\nResearch Philosophy: [I am taking a needs-driven approach because...]\n\nSignificance/Impact:\n- \n- \n- \n\nKey Terms Defined:\n- Term 1: Definition\n- Term 2: Definition\n\nTarget Audience/Stakeholders:\n1. \n2. \n3. \n4. \n5. "
      },
      "llmInstructions": "Above, I wrote down my scientific question and research philosophy. I also wrote down why this question is important to me and who else would be interested. I want you to check if the question feels like a good question for scientific inquiry and if the research philosophy aligns well with the question. Please evaluate:\n\n1. Strengths and weaknesses of the question (including clarity of terms and scope)\n2. Whether the research philosophy (hypothesis testing, exploratory, or needs-driven) is appropriate for the question\n3. How well the question matches my stated significance/objectives\n4. Whether the listed audience/community would truly find this question interesting\n\nPlease also suggest 3-5 additional professors, researchers, or specific communities who might be especially interested in this topic. If my research philosophy isn't explicit or doesn't align with my question, help me refine both to create a coherent research approach."
    },
    {
      "id": "hypothesis",
      "title": "Hypothesis",
      "type": "text",
      "maxLength": 2000,
      "inputPlaceholder": "Start writing your hypotheses here...",
      "completeButtonText": "MARK COMPLETE",
      "loadingButtonText": "Analyzing hypotheses...",
      "instructions": {
        "title": "Developing Testable Hypotheses",
        "text": "Based on your research question (especially if hypothesis-testing), formulate *at least two* plausible and distinct explanations or predictions.\n\n### Key Requirements for Strong Hypotheses:\n\n1.  **Testable & Falsifiable:** Each hypothesis must be formulated so that your planned experiment could potentially prove it wrong.\n2.  **Specific & Clearly Defined:** Define all key terms within each hypothesis precisely. Avoid ambiguity.\n3.  **Distinguishable:** Your experiment's data should be able to clearly differentiate between the hypotheses. They should predict different outcomes.\n4.  **Consequential:** The answer should matter. Distinguishing between these hypotheses should change how you or others think about or approach the field.\n\n### Actions:\n\n* **Draft Your Hypotheses:** Write down at least two specific, testable hypotheses.\n* **Define Terms:** Clearly define any ambiguous terms within your hypotheses.\n* **State Relevance:** Explain *why* it is important to distinguish between these specific hypotheses.\n* **Consider Scope:** Define the conditions or boundaries under which each hypothesis is expected to hold.\n* **(Optional but Recommended):** Express hypotheses mathematically or via computational models if possible.\n* **Identify Prior Work:** List ~5 key papers testing the most similar hypotheses to situate your work.\n* **Refine:** Be prepared to revisit and refine these as you design your experiment and analysis plan."
      },
      "placeholder": "Hypothesis 1: [State the first specific, testable hypothesis. Define key terms within it.]\n\nHypothesis 2: [State the second specific, testable hypothesis, distinct from H1. Define key terms within it.]\n\nTerms Defined:\n- Term H1.1: Definition\n- Term H2.1: Definition\n\nWhy distinguishing these hypotheses matters:\n- \n- \n\nMost similar papers that test related hypotheses:\n1. \n2. \n3. \n4. \n5. ",
      "placeholders": {
        "hypothesis": "Hypothesis 1: [State the first specific, testable hypothesis. Define key terms within it.]\n\nHypothesis 2: [State the second specific, testable hypothesis, distinct from H1. Define key terms within it.]\n\nTerms Defined:\n- Term H1.1: Definition\n- Term H2.1: Definition\n\nWhy distinguishing these hypotheses matters:\n- \n- \n\nMost similar papers that test related hypotheses:\n1. \n2. \n3. \n4. \n5. ",
        "exploratory": "Area 1 to explore: [Define the first area/pattern/relationship to investigate. Define key terms.]\n\nArea 2 to explore: [Define the second area/pattern/relationship to investigate. Define key terms.]\n\nTerms Defined:\n- Term A1.1: Definition\n- Term A2.1: Definition\n\nWhy exploring these areas matters:\n- \n- \n\nMost similar exploratory papers in this field:\n1. \n2. \n3. \n4. \n5. ",
        "needs": "Proposed solution 1: [Describe the first proposed solution/approach. Define key metrics/terms.]\n\nProposed solution 2: [Describe the second proposed solution/approach to compare. Define key metrics/terms.]\n\nTerms Defined:\n- Term S1.1: Definition\n- Term S2.1: Definition\n\nWhy comparing these solutions matters:\n- \n- \n\nMost similar solution-oriented papers:\n1. \n2. \n3. \n4. \n5. "
      },
      "llmInstructions": "Only work on the hypotheses at first but if the hypotheses feel roughly ready feel free to refer the user back to the questions if a change there may be warranted by the hypotheses. Above I wrote down the scientific hypotheses I want to test (or areas/solutions). I also wrote down why it matters to distinguish these. I also wrote out a list of relevant papers. I want you to list the strengths and weaknesses of the hypotheses/areas/solutions, particularly regarding specificity and testability/feasibility. Check if distinguishing between them would be consequential, if it would change the research others would do or lead to products. Check if they are mutually exclusive (if applicable). Check if key terms are well-defined. I want you to check to which level the listed papers are among the closest to the proposed work and to also supply a list of five more papers that may be more relevant."
    },
    {
      "id": "experiment",
      "title": "Experiment",
      "type": "text",
      "maxLength": 2500,
      "inputPlaceholder": "Start designing your experiment here...",
      "completeButtonText": "SUBMIT DESIGN FOR REVIEW",
      "loadingButtonText": "Analyzing experimental design...",
      "instructions": {
        "title": "Designing a Rigorous Experiment",
        "text": "Design an experiment that can generate high-quality data to **directly and convincingly distinguish** between your hypotheses (or address your exploratory/needs-driven goals).\n\n### Key Design Components:\n\n1.  **Procedure:** Detail the step-by-step process.\n    * Define key **variables** (independent, dependent, controlled).\n    * Describe **stimulus protocols** and/or interventions.\n    * List **apparatus and materials**.\n    * Specify **control groups/conditions** needed to isolate effects and rule out alternatives.\n    * Describe the **sample** (characteristics, recruitment strategy) and justify the **sample size** (consider statistical power).\n    * Outline specific **data collection procedures**.\n\n2.  **Predicted Outcomes:** Clearly state how the *measurable data* collected will differ depending on which hypothesis is correct (or what patterns/outcomes are expected).\n\n3.  **Rigor & Bias Control:** Implement practices to minimize bias and ensure robust findings. Consider:\n    * **Directness:** Does the design test the hypotheses as directly as possible? Avoid unnecessary complexity.\n    * **Controls:** Are the control conditions appropriate and sufficient?\n    * **Randomization:** Use randomization where appropriate (e.g., assigning subjects to groups, stimulus order) to minimize allocation bias.\n    * **Blinding:** Implement single or double blinding if subjective measurements or human evaluations are involved, to prevent observer bias.\n    * **Power & Validity:** Is the sample size adequate? Does the sample support internal validity (confidence in findings for *this* sample)? Consider factors affecting external validity (generalizability).\n    * **Confounders:** Identify potential confounding variables and plan how to measure or control them.\n    * **Validation & Calibration:** Ensure any datasets, software, reagents, or instruments are validated and calibrated for your purpose.\n    * **Ethics:** Plan for and obtain necessary ethical approvals (e.g., IRB, ACUC). Ensure ethical conduct throughout.\n\n4.  **Documentation:** Plan to document the protocol in sufficient detail for reproducibility.\n\n### Actions:\n\n* **Outline the design** covering the components above.\n* **Focus on distinction:** How will the results specifically differentiate your hypotheses or achieve your goals?\n* **Address rigor:** Explicitly consider which rigor elements are most critical for your design and how you will address them.\n* **Simulate (Optional):** Consider simulating the experiment and analysis to refine the design."
      },
      "placeholder": "Experimental Design:\n[Overall approach, e.g., between-subjects, within-subjects, mixed design]\n\nKey Variables:\n- Independent: \n- Dependent: \n- Controlled: \n\nStimulus Protocol/Intervention: \n\nApparatus/Materials: \n\nControl Group/Condition: \n\nSample Characteristics & Recruitment: \n\nSample Size Justification (Power Considerations): \n\nData Collection Procedure: \n\nPredicted Results:\n- If Hypothesis 1 is correct: [Describe specific, measurable outcome]\n- If Hypothesis 2 is correct: [Describe specific, measurable outcome, distinct from H1's prediction]\n\nPotential Confounds & Mitigations:\n1. [Confound] -> [Mitigation strategy]\n2. \n\nEthical Considerations:\n[IRB/ACUC status or plan, consent process, data anonymization, etc.]",
      "placeholders": {
        "hypothesis": "Experimental Design:\n[Overall approach, e.g., between-subjects, within-subjects, mixed design]\n\nKey Variables:\n- Independent: \n- Dependent: \n- Controlled: \n\nStimulus Protocol/Intervention: \n\nApparatus/Materials: \n\nControl Group/Condition: \n\nSample Characteristics & Recruitment: \n\nSample Size Justification (Power Considerations): \n\nData Collection Procedure: \n\nPredicted Results:\n- If Hypothesis 1 is correct: [Describe specific, measurable outcome]\n- If Hypothesis 2 is correct: [Describe specific, measurable outcome, distinct from H1's prediction]\n\nPotential Confounds & Mitigations:\n1. [Confound] -> [Mitigation strategy]\n2. \n\nEthical Considerations:\n[IRB/ACUC status or plan, consent process, data anonymization, etc.]",
        "exploratory": "Data Collection Approach:\n[Methodology, e.g., survey, observational study, physiological recording]\n\nSampling Strategy: [How participants/data points will be selected]\n\nMeasurement Tools: [Instruments, software, questionnaires used]\n\nSample Characteristics & Recruitment: \n\nSample Size Justification (if applicable, e.g., for detecting patterns of a certain magnitude): \n\nData Collection Procedure: \n\nExpected Data Patterns:\n- Potential pattern 1: [Description of possible outcome/relationship]\n- Potential pattern 2: [Description of alternative outcome/relationship]\n\nPotential Biases & Mitigations:\n1. [Bias, e.g., selection bias, measurement bias] -> [Mitigation strategy]\n2. \n\nEthical Considerations:\n[IRB/ACUC status or plan, consent process, data anonymization, etc.]",
        "needs": "Implementation & Evaluation Approach:\n[Overall methodology, e.g., Agile development, A/B testing, user-centered design]\n\nDesign Methodology: [Specific techniques used for creating the solution]\n\nRequired Resources: [Personnel, equipment, software, funding]\n\nUser/Stakeholder Involvement Plan: [How users will participate in testing/feedback]\n\nData Collection for Evaluation: [Metrics, surveys, logs]\n\nSuccess Criteria (Measurable):\n- For Solution 1 (or baseline): [Specific metric and target value]\n- For Solution 2 (or proposed): [Specific metric and target value]\n\nPotential Challenges & Mitigations:\n1. [Challenge, e.g., technical hurdle, user adoption] -> [Mitigation strategy]\n2. \n\nEthical Considerations:\n[Data privacy, informed consent for user studies, potential impacts of the solution]"
      },
      "llmInstructions": "Only work on experimental design step. See the instructions above and guide the user interactively towards designing a good experiment given questions and hypotheses (or exploration goals/problem statement). Consider that question and hypotheses may also require revision. Use Socrates method where possible. I want you to guide the discussion to the following topics: Check if the experiment *directly* tests the hypotheses/addresses the goals. Check if the predicted outcomes for each hypothesis are truly distinct and measurable. Go through the 'Key Rigor Considerations' (blinding, controls, randomization, power, etc.) mentioned in the instructions and help the user ensure their design appropriately addresses the relevant ones. Focus on the ones that matter most for their specific design. Interactively refine the design with the user, being constructive and making proposals to improve clarity, directness, and rigor."
    },
    {
      "id": "analysis",
      "title": "Data Analysis",
      "type": "text",
      "maxLength": 3000,
      "inputPlaceholder": "Start planning your data analysis here...",
      "completeButtonText": "MARK COMPLETE",
      "loadingButtonText": "Processing...",
      "instructions": {
        "title": "Pre-Specifying Your Data Analysis Plan",
        "text": "Define precisely how you will analyze your data to objectively evaluate your hypotheses or address your goals *before* you look at the results from your main experiment.\n\n### Core Principle: Pre-specification\n\n* **Plan First:** Define your primary analysis pipeline in detail *before* analyzing the experimental data. This minimizes bias.\n* **Consider Pre-registration:** Strongly consider formally pre-registering your plan (e.g., on OSF, AsPredicted) to maximize transparency and credibility.\n\n### Key Analysis Components:\n\n1.  **Data Pipeline:** Outline the steps from raw data to results.\n    * **Preprocessing:** Detail cleaning steps, data formatting, exclusion criteria (with justification), and handling of missing data.\n    * **Outlier Strategy:** Specify how potential outliers will be identified and handled.\n    * **Primary Analysis:** Define the main statistical method(s) or model(s) you will use (e.g., t-test, ANOVA, regression, specific ML algorithm).\n    * **Secondary/Exploratory Analyses:** List any planned secondary analyses, clearly labeling them as exploratory (to be interpreted with more caution).\n\n2.  **Linking Analysis to Goals:**\n    * **Hypothesis Distinction:** Explain exactly how the results of the primary analysis (e.g., specific metrics, statistical values) will allow you to distinguish between your hypotheses or characterize patterns/evaluate solutions.\n    * **Uncertainty Quantification:** State how you will report uncertainty (e.g., p-values with alpha level, confidence intervals, Bayesian credible intervals/Bayes Factors).\n    * **Parameter Handling:** If using models, describe how free parameters will be estimated or set.\n\n3.  **Rigor and Transparency:**\n    * **Directness:** Use the simplest, most direct analysis strategy appropriate for your question.\n    * **Avoid Outcome Switching:** Stick to your pre-specified primary outcome(s) and analysis. Do not change them based on results.\n    * **Multiple Comparisons:** If conducting multiple tests, specify your correction method (e.g., Bonferroni, FDR).\n    * **Reproducibility:** Plan to script your analysis and manage data/code systematically for reproducibility.\n    * **Appropriate Metrics:** Ensure your chosen metrics accurately reflect the phenomenon of interest.\n    * **Data Leakage (ML):** If using ML, ensure strict separation of training and test data.\n\n### Actions:\n\n* **Outline your analysis plan** covering the components above.\n* **Validate (Optional):** Test your analysis pipeline on simulated or pilot data.\n* **Log Changes:** If deviations from the pre-specified plan become necessary during analysis, document them transparently with justifications."
      },
      "placeholder": "Data Preprocessing:\n- Cleaning steps:\n- Exclusion criteria:\n- Missing data handling:\n\nOutlier Handling Strategy:\n\nPrimary Analysis Method(s):\n[Specify the statistical test(s) or model(s)]\n\nHypothesis Distinction / Goal Addressment:\n[Explain how the analysis output relates back to the hypotheses/goals]\n\nUncertainty Quantification:\n[e.g., Significance level alpha=0.05, Report 95% CIs, Use Bayesian credible intervals]\n\nParameter Handling (if applicable):\n\nMultiple Comparisons Correction (if applicable):\n\nSecondary/Exploratory Analyses (Optional):\n",
      "placeholders": {
        "hypothesis": "Data Preprocessing:\n- Cleaning steps:\n- Exclusion criteria:\n- Missing data handling:\n\nOutlier Handling Strategy:\n\nPrimary Analysis Method(s):\n[Specify the statistical test(s) or model(s)]\n\nHypothesis Distinction:\n[Explain how the analysis output (e.g., p-value, effect size, model comparison) distinguishes between H1 and H2]\n\nUncertainty Quantification:\n[e.g., Significance level alpha=0.05, Report 95% CIs, Use Bayesian credible intervals/BFs]\n\nParameter Handling (if applicable):\n\nMultiple Comparisons Correction (if applicable):\n\nSecondary/Exploratory Analyses (Optional):\n",
        "exploratory": "Data Preprocessing:\n- Cleaning steps:\n- Data transformation (if any):\n- Exclusion criteria:\n\nOutlier Handling Strategy:\n\nPrimary Analysis Method(s):\n[Specify exploratory techniques, e.g., PCA, clustering, visualization methods]\n\nPattern Characterization:\n[Explain how the analysis output will identify and describe patterns/relationships]\n\nUncertainty Quantification (if applicable):\n[e.g., Bootstrapping for stability, cross-validation]\n\nParameter Handling (if applicable):\n\nMultiple Comparisons Correction (if applicable):\n\nSecondary Analyses (Optional):\n",
        "needs": "Data Preprocessing:\n- Cleaning steps:\n- Feature engineering (if any):\n- Handling user feedback data:\n\nOutlier Handling Strategy:\n\nPrimary Evaluation Method(s):\n[Specify metrics and comparison method, e.g., compare Metric X between Solution 1 and 2 using a paired t-test]\n\nSolution Assessment:\n[Explain how the evaluation results determine if success criteria are met and which solution is preferred]\n\nUncertainty Quantification:\n[e.g., Significance level alpha=0.05 for comparisons, CIs on metrics]\n\nParameter Handling (if applicable):\n\nMultiple Comparisons Correction (if applicable):\n\nSecondary Analyses (Optional):\n[e.g., Subgroup analysis, qualitative feedback analysis]"
      },
      "llmInstructions": "Check the analysis plan. Does it logically follow from experiment and hypotheses? Does it seem sound? Does it quantify results in a meaningful way? Use a constructive dialogue to refine the plan, asking about specific choices (e.g., 'Why this statistical test?', 'How will you handle missing data?'). Discuss potential pitfalls like p-hacking or lack of power. If the user plans exploratory analyses, ensure they are clearly labeled as such."
    },
    {
      "id": "process",
      "title": "Process",
      "type": "text",
      "maxLength": 3000,
      "inputPlaceholder": "Outline your process, skills, and timeline...",
      "completeButtonText": "MARK COMPLETE",
      "loadingButtonText": "Processing...",
      "instructions": {
        "title": "Planning Your Research Process",
        "text": "Plan the practical execution of your research, considering skills, resources, collaboration, and timeline.\n\n### Key Planning Areas:\n\n1.  **Skills Assessment:**\n    * **Identify Needs:** List the key conceptual, experimental, and analytical/coding skills required.\n    * **Self-Assess:** Honestly evaluate which skills you currently possess.\n    * **Plan for Gaps:** Determine which skills you need to acquire (and how, e.g., training, workshops) or secure through collaboration.\n\n2.  **Collaboration Plan (if applicable):**\n    * **Identify Needs:** Specify areas where collaboration is necessary.\n    * **Potential Partners:** List potential collaborators or labs.\n    * **Logistics:** Outline how communication, roles, and responsibilities will be managed.\n\n3.  **Reproducibility & Sharing Plan:** Remember you're collaborating with your future self!\n    * **Documentation:** Plan *how* you will document methods and analyses thoroughly (e.g., detailed lab notebook protocols, well-commented code).\n    * **Sharing Strategy:** Outline your plan for sharing data and code (e.g., repository choice like OSF, GitHub, Zenodo; data formats like BIDS/CSV; documentation standards; licensing like CC-BY/MIT).\n\n4.  **Project Timeline:**\n    * **Major Phases:** Break the project into key phases (e.g., Preparation/Setup, Data Collection, Analysis, Writing).\n    * **Estimate Duration:** Realistically estimate the time needed for each phase.\n    * **Identify Bottlenecks:** Foresee potential obstacles for each phase.\n    * **Contingency Planning:** Develop backup plans for anticipated obstacles (remember: tasks often take longer than expected).\n\n### Actions:\n\n* **Outline your plan** covering these four areas.\n* **Be realistic** in your assessments and estimations."
      },
      "placeholder": "Skills Assessment:\n- Skills Needed: \n  1. [Conceptual Skill, e.g., Understanding theory X]\n  2. [Experimental Skill, e.g., Performing technique Y]\n  3. [Analytical Skill, e.g., Statistical modeling in R]\n- Skills I Have: \n- Skills to Acquire/Learn: [Skill + Plan, e.g., Take online course on Z]\n\nCollaboration Plan:\n- Collaborations Required: [e.g., Need collaborator with expertise in A]\n- Potential Collaborators: \n- Communication Plan: \n\nData/Code Sharing Plan:\n- Documentation: [e.g., Use electronic lab notebook, comment code extensively]\n- Repository: [e.g., Data on OSF, Code on GitHub]\n- Data Format: [e.g., BIDS for neuroimaging data, CSV for tables]\n- Licensing: [e.g., CC-BY for data, MIT for code]\n\nProject Timeline:\n- Phase 1 (Preparation/Setup): [Tasks + Estimated Time, e.g., Ethics approval, Order materials - 2 months]\n- Phase 2 (Data Collection): [Tasks + Estimated Time, e.g., Recruit & run 30 participants - 4 months]\n- Phase 3 (Analysis): [Tasks + Estimated Time, e.g., Preprocessing, Primary analysis - 3 months]\n- Phase 4 (Writing): [Tasks + Estimated Time, e.g., Draft manuscript, Revisions - 3 months]\n- TOTAL ESTIMATED TIME: [Sum of phases]\n\nPotential Obstacles & Contingency Plans:\n1. Obstacle: [e.g., Slow participant recruitment] -> Contingency: [e.g., Expand recruitment sites, Offer slightly higher compensation]\n2. Obstacle: [e.g., Key equipment failure] -> Contingency: [e.g., Identify backup equipment access]\n3. Obstacle: [e.g., Analysis code bug] -> Contingency: [Allocate extra debugging time, seek expert help]",
      "placeholders": {
        "hypothesis": "Skills Assessment:\n- Skills Needed: \n  1. \n  2. \n  3. \n- Skills I Have: \n- Skills to Acquire/Learn: \n\nCollaboration Plan:\n- Collaborations Required: \n- Potential Collaborators: \n- Communication Plan: \n\nData/Code Sharing Plan:\n- Documentation: \n- Repository: \n- Data Format: \n- Licensing: \n\nProject Timeline:\n- Phase 1 (Preparation): \n- Phase 2 (Data Collection): \n- Phase 3 (Analysis): \n- Phase 4 (Writing): \n- TOTAL ESTIMATED TIME: \n\nPotential Obstacles & Contingency Plans:\n1. Obstacle:  -> Contingency: \n2. ",
        "exploratory": "Skills Assessment:\n- Skills Needed: \n  1. \n  2. \n  3. \n- Skills I Have: \n- Skills to Acquire/Learn: \n\nCollaboration Plan:\n- Collaborations Required: \n- Potential Collaborators: \n- Communication Plan: \n\nData/Code Sharing Plan:\n- Documentation: \n- Repository: \n- Data Format: \n- Licensing: \n\nProject Timeline:\n- Phase 1 (Preparation): \n- Phase 2 (Data Collection): \n- Phase 3 (Exploratory Analysis): \n- Phase 4 (Pattern Validation/Follow-up): \n- Phase 5 (Writing): \n- TOTAL ESTIMATED TIME: \n\nPotential Obstacles & Contingency Plans:\n1. Obstacle:  -> Contingency: \n2. ",
        "needs": "Skills Assessment:\n- Skills Needed: \n  1. \n  2. \n  3. \n- Skills I Have: \n- Skills to Acquire/Learn: \n\nCollaboration Plan:\n- Collaborations Required: \n- Potential Collaborators/Stakeholders: \n- Communication Plan: \n\nSolution Deployment & Sharing Plan:\n- Documentation: [User guides, technical docs]\n- Repository/Distribution: [e.g., GitHub, App Store, internal server]\n- Licensing: \n\nProject Timeline:\n- Phase 1 (Requirements Gathering): \n- Phase 2 (Design): \n- Phase 3 (Implementation): \n- Phase 4 (Testing/Evaluation): \n- Phase 5 (Deployment/Rollout): \n- TOTAL ESTIMATED TIME: \n\nPotential Obstacles & Contingency Plans:\n1. Obstacle:  -> Contingency: \n2. "
      },
      "llmInstructions": "I want you to check the resulting processes and skills statements. Does the skills assessment seem realistic? Are the identified collaborations appropriate? Is the data/code sharing plan sufficiently detailed for reproducibility? Brainstorm anything that might be missing in an interactive way (e.g., specific training needs, data management details). Critically evaluate the timeline – does it seem realistic given the tasks? Are the obstacles plausible and contingencies adequate? Brainstorm potential timeline problems or overlooked dependencies."
    },
    {
      "id": "abstract",
      "title": "Abstract",
      "type": "text",
      "maxLength": 1500,
      "inputPlaceholder": "Draft your abstract here...",
      "completeButtonText": "MARK COMPLETE",
      "loadingButtonText": "Processing...",
      "instructions": {
        "title": "Drafting an Abstract to Test Coherence",
        "text": "Writing an abstract now serves as a powerful check for the overall coherence and logical flow of your research plan.\n\n### Purpose:\n\n* **Summarize:** Condense your entire project into a brief overview.\n* **Check Logic:** Ensure all components (Question, Hypothesis/Goal, Experiment, Analysis) fit together seamlessly.\n* **Identify Weaknesses:** Drafting the abstract often reveals inconsistencies or areas needing refinement in your plan.\n\n### Structure (Aim for 1-2 sentences per point):\n\n1.  **Background:** Briefly introduce the research area, identify the knowledge gap or problem, and state its significance.\n2.  **Objective/Question:** Clearly state the main research question, primary hypothesis being tested, exploration goal, or problem being solved.\n3.  **Methods:** Concisely summarize the core aspects of your experimental design, participants/sample, and key procedures or analytical techniques.\n4.  **(Expected) Results:** Briefly describe the main anticipated findings and, crucially, how they will address the objective or distinguish between hypotheses.\n5.  **Conclusion/Implications:** State the main takeaway message (even if speculative at this stage) and its potential broader impact on the field or application.\n\n### Actions:\n\n* **Draft your abstract** following this structure.\n* **Review:** Compare the abstract against your detailed plans in the previous sections (Question, Hypothesis, Experiment, Analysis). Does it accurately reflect the core elements?\n* **Refine:** Use any inconsistencies identified during abstract writing to improve the earlier sections of your plan.\n* **(Optional):** Share the draft with a peer for feedback on clarity and coherence."
      },
      "placeholder": "Background: [Introduce field, gap, significance. 1-2 sentences]\n\nObjective/Question: [State primary aim/question/hypothesis. 1 sentence]\n\nMethods: [Briefly describe design, participants, key procedures. 1-2 sentences]\n\n(Expected) Results: [Summarize anticipated main finding and how it addresses the objective. 1-2 sentences]\n\nConclusion/Implications: [State main conclusion and broader impact. 1-2 sentences]",
      "placeholders": {
        "hypothesis": "Background: [Field context, knowledge gap, intuitive hypothesis, significance. 1-2 sentences]\n\nObjective/Question: [State the specific hypothesis being tested. 1 sentence]\n\nMethods: [Briefly describe design, participants, key methods used to test hypothesis. 1-2 sentences]\n\n(Expected) Results: [Summarize anticipated finding and how it distinguishes between hypotheses. 1-2 sentences]\n\nConclusion/Implications: [State conclusion regarding hypothesis and implications for the field. 1-2 sentences]",
        "exploratory": "Background: [Field context, area lacking exploration, significance of exploring it. 1-2 sentences]\n\nObjective/Question: [State the main goal of the exploration (e.g., identify patterns in X). 1 sentence]\n\nMethods: [Briefly describe data source, sample, key exploratory techniques used. 1-2 sentences]\n\n(Expected) Results: [Summarize anticipated key patterns or discoveries. 1-2 sentences]\n\nConclusion/Implications: [State potential impact of findings and implications for future hypothesis-driven research. 1-2 sentences]",
        "needs": "Background: [Problem context, affected stakeholders, importance of solving it. 1-2 sentences]\n\nObjective/Question: [State the goal (e.g., develop/evaluate solution X for problem Y). 1 sentence]\n\nMethods: [Briefly describe solution development approach and evaluation method. 1-2 sentences]\n\n(Expected) Results: [Summarize anticipated effectiveness or key outcome of the solution based on evaluation metrics. 1-2 sentences]\n\nConclusion/Implications: [State conclusion about solution's potential and implications for stakeholders/field. 1-2 sentences]"
      },
      "llmInstructions": "I want you to check the resulting abstract. Does it logically follow from the previous sections (Question, Hypothesis, Experiment, Analysis)? Does it adhere to the requested structure (Background, Objective, Methods, Results, Conclusion)? Is it convincing and clearly written? Is the language precise? What specific changes (e.g., word choice, sentence structure) would make it more powerful or clear? Use a constructive, Socratic dialogue style. Help the user reflect on what they learned by going through this planning process. Ask what they might do differently next time they plan a study."
    }
  ]
}

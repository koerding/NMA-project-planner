{
  "title": "Scientific Paper Planner Sections",
  "sections": [
    {
      "id": "question",
      "title": "Research Question",
      "type": "text",
      "maxLength": 3000,
      "inputPlaceholder": "Start writing your research question here...",
      "instructions": {
        "title": "Formulating Your Research Question",
        "text": "A strong research question is the foundation of a successful project. It defines the scope, focus, and purpose of your work and guides all decisions from design to analysis. A well-formulated question ensures clarity, relevance, and feasibility. \n\n **Question Clarity: Make sure the research question is clearly and unambiguously stated?**  A well-formed question should be understandable on its own. Avoid vague terms unless you define them. Ideally, a peer from your program should know what you are asking just by reading this sentence or two. *Clarity anchors your entire research endeavor. When your question is unambiguous, it helps align your methods, data collection, and interpretation. It also gives peers and advisors an immediate grasp of what you’re investigating, making their feedback more targeted and constructive. Ambiguity, on the other hand, can lead to misaligned expectations or conflicting interpretations. By defining each term and concept up front, you reduce confusion, create a strong foundation for hypothesis building, and facilitate clearer communication. Ultimately, the clearer your research question, the more coherent and persuasive your final dissertation will be.* \n\n **Motivation and Importance: Make sure to clearly explain why this question matters, to you and to the field?** This part is just as important as the question itself. Why care? What is exciting about it? Make sure the scientific stake is clear: What changes if we know the answer? Why would others in the field care? What problem, gap, or idea does it speak to? *Motivation breathes life into your research question. By pinpointing why the question matters, you show its relevance and potential impact on both theory and practice. A strong rationale helps you stand out in a crowded field, secures backing from mentors or funding agencies, and keeps you personally invested. Researchers—especially reviewers—want to see a clear “so what” behind your work. Clarifying the potential changes or insights that might follow from answering the question not only strengthens your case for doing the research, but also helps you stay focused on the broader context that gives your study true significance.* \n\n **Specificity and Scope: The question should be focused enough to be answered within the scope of your project.** If the question feels like it could lead to ten dissertations, it needs to be narrowed. Aim for a piece of the puzzle that is tractable but still meaningful. *Striking the right balance between ambition and feasibility is critical for a good project. If your question is too large, you risk superficial coverage of many sub-areas without achieving depth in any one. An overly narrow focus might, conversely, limit the broader impact of your research. By defining a specific scope, you ensure each chapter or experiment directly addresses a piece of your core question. This focus strengthens methodological choices, clarifies data collection needs, and makes your findings more cohesive. A well-scoped question also supports a timely completion, since you can plan tasks and milestones around a realistic, measurable research aim.* \n\n **Type of Question: Is it clear whether the question is descriptive (what), mechanistic (how), or explanatory/causal (why)?** You don’t have to use these exact terms, but you should know what kind of answer you’re aiming for — and make sure your framing supports it. *Before diving into data or experiments, identify whether your question aims to characterize an unknown phenomenon, reveal the processes behind it, or determine cause-effect relationships. This distinction shapes everything: from the design of your study to the analytical tools you use. A descriptive question, for instance, might rely on observational data, while a mechanistic or causal question demands more controlled or comparative studies. By clarifying the nature of your question at the outset, you guide your own research decisions and help readers anticipate the kind of evidence or argument you’ll provide. It also keeps you from conflating correlation with causation.*"
      },
      "placeholder": "Research Question:[Write it out] \n\nSignificance/Impact: [Why it matters]\n",
      "llmInstructions": "Please review my research question and significance statement and provide feedback. Does my question have clarity, importance, appropriate scope, and a clear type (descriptive, mechanistic, or causal)? What specific improvements would you suggest?"
    },
    {
      "id": "audience",
      "title": "Target Audience",
      "type": "text",
      "maxLength": 1500,
      "inputPlaceholder": "List the target audience for your research...",
      "instructions": {
        "title": "Identifying Your Target Audience",
        "text": "Knowing your target audience helps ensure your work reaches and resonates with the right people. Identifying relevant communities, researchers, or stakeholders lets you tailor your communication and maximize impact. It also guides choices around framing, methods, and venues for dissemination. \n\n **Key Audiences: Say who in the research world would care about this work.** List relevant communities, fields, or subfields. Be specific. *Identifying your audience focuses your communication and shapes the style of your writing or presentations. Different subfields, for example, often have their own jargon or methodological norms, so clarity on which groups will benefit helps you tailor content. This knowledge can guide decisions about which journals to target or which conferences to attend. Specifying audiences also fosters potential collaborations, as like-minded researchers may realize your project intersects with their interests. Ultimately, knowing your audience from the start helps you craft a coherent and compelling message for those most likely to build on your findings.* \n\n **Impact on Each Audience: Briefly explain how your work could matter to them.** Is it a new method they can use? A surprising result they’ll want to understand? *When you articulate the benefits for each audience, you make your research more accessible and inviting. Maybe statisticians gain a novel computational approach, while clinicians get a diagnostic tool that streamlines patient care. Pinpointing these implications demonstrates you’ve considered multiple perspectives and fosters trust in the relevance of your work. It can also shape your discussion section—highlighting different takeaways for each group. By framing each audience’s potential gains, you lay the groundwork for future collaborations, broader adoption of your techniques, or greater acceptance of your hypotheses.* \n\n **Representative Individuals: Name specific labs or researchers as examples.** This helps you picture your actual audience — and maybe ask them for feedback. *Selecting concrete examples of who might benefit ensures you’re not just imagining a nebulous group. By naming labs, research centers, or influential scholars, you can better envision their needs and expectations. This specificity often leads to more practical research decisions: you can adopt methodologies or data standards that you know these groups use. It may also encourage direct outreach—perhaps sharing a draft with a researcher whose work closely relates. Incorporating feedback from people you’ve explicitly identified fosters a dynamic, real-world relevance, increasing the chances your final output resonates outside your immediate circle.* \n\n **Tailoring Communication: Think about how to adjust framing or methods for different groups.** If you are speaking to multiple audiences, consider differences in terminology or expectations. *One of the biggest barriers to disseminating research effectively is failing to account for diverse backgrounds. Engineers might value technical specifications, while psychologists focus on theoretical frameworks. Clinicians may need concise, actionable summaries instead of in-depth statistical detail. By tailoring your message, you ensure each audience can see the value of your work without getting lost or bored. This strategy also extends to how you present data—visual formats, examples, or anecdotal evidence might resonate with one group more than another. Recognizing these differences early helps you build your final deliverables in a flexible, impactful way.*"
        },
        "placeholder": "Target Audience/Community (research fields/disciplines):\n1. \n2. \n3. \n\nSpecific Researchers/Labs (individual scientists or groups):\n1. \n2. \n3. ",
        "llmInstructions": "Please review my target audience section. Have I clearly identified key audiences, explained how my work matters to them, named specific researchers/labs, and considered communication strategies? What specific improvements would make this section stronger?"
    },
    {
      "id": "hypothesis",
      "title": "Hypothesis",
      "type": "text",
      "maxLength": 2000,
      "inputPlaceholder": "Start writing your hypotheses here...",
      "instructions": {
        "title": "Hypothesis-driven Research",
        "text": "Hypotheses translate your research question into specific, testable ideas. They clarify what you are trying to discover or differentiate and provide structure for your experimental or analytical design. Clear hypotheses improve transparency and strengthen the logic of your work. **Alignment With Your Question: Hypotheses should directly reflect and address your research question.** Make sure your hypotheses flow logically from your Research Question. They must be plausible answers to that question, not independent ideas. *Strong hypotheses are rooted in the overarching research question, translating it into testable predictions. This close alignment avoids scattered or unrelated explorations that fail to advance your core inquiry. When hypotheses naturally grow out of your question, you create a clean line of reasoning that helps you design effective experiments and analyses. Reviewers often check for this consistency as a marker of well-structured research. Moreover, the process of deriving hypotheses from the question forces you to articulate what, specifically, you expect to learn—paving the way for more robust and conclusive interpretations.* \n\n **Formulate 2+ Distinct Hypotheses:Each hypothesis should be specific and testable.** If possible, propose multiple hypotheses that differ in real ways. Avoid vague generalities. *Having more than one clear, testable hypothesis demonstrates that you’ve considered multiple outcomes or explanations. This approach strengthens your research design by revealing possible twists or turns in the data. Instead of betting on a single result, you’re genuinely probing the phenomenon from multiple angles, which is the essence of scientific rigor. Distinct hypotheses also sharpen your analytical plan, ensuring you collect and interpret data that can differentiate among them. If each hypothesis is well-defined, readers can see exactly how you’ll measure success or failure for each scenario, enhancing the study’s transparency and credibility.* **Ability to Differentiate: Your study must allow you to tell these hypotheses apart.** If your data can not actually differentiate your hypotheses, you need to revise them or rethink your design. *Proposing multiple hypotheses only matters if your methods and data can separate one possibility from another. It’s crucial to identify the metrics, experimental conditions, or statistical thresholds that would support one hypothesis while undermining the others. This clarity of measurement and analysis is foundational for meaningful findings. Without it, you risk ambiguous interpretations or arguments that any result fits. Planning in advance for how you’ll distinguish among hypotheses shows that you’re serious about testing alternative ideas. It also keeps your study from falling into the trap of confirming a single perspective simply because the design wasn’t set up to refute it.* \n\n **Scientific Importance:Explain why distinguishing between these hypotheses matters to science and to you.** What do we learn if hypothesis A is right? What if B is? Why do you care? Why should others? *Hypotheses are most valuable when each potential outcome tells a different and meaningful story. By articulating the importance of each hypothetical result, you demonstrate the intellectual merit of your project. Whether the finding supports one hypothesis or another, the field stands to learn something tangible. This significance can range from resolving a debated mechanism to illuminating an entirely novel phenomenon. For your own motivation, framing the hypotheses’ importance also keeps you engaged—knowing that your work might clarify core issues in the literature or inspire new lines of inquiry. Such framing is often persuasive for funding bodies and conference audiences too.* \n\n ** Data and Decision: Show how results will help you decide between hypotheses.** Reference how your analysis plan will reveal support for one hypothesis over another. *Before you collect data, specify how you will interpret potential outcomes in the context of your hypotheses. Are you looking for significant differences in a key variable? Do you expect certain correlations to hold true only under one hypothesis? By tying each anticipated pattern to a particular hypothesis, you streamline your analysis. This approach also promotes transparency: readers can see upfront that you’re not cherry-picking findings later. When you connect data expectations to a specific decision rule—like a p-value cutoff, a Bayesian odds ratio, or a predicted effect size—it’s easier for others to gauge the strength of your conclusions.* \n\n **Avoid HARKing: Don’t write your hypotheses after seeing results.** If you find something new post hoc, label it exploratory. Don’t revise history. *HARKing (Hypothesizing After the Results are Known) dilutes scientific integrity and confuses the narrative of how findings emerged. While it’s natural to refine your thinking once you see unexpected data, ethical practice dictates you label that shift as exploratory or post hoc. This honesty fosters clearer research records and helps avoid misleading others about the nature of your inquiry. It also paves the way for follow-up studies that formally test new ideas. By upfront labeling and avoiding retroactive hypothesis creation, you preserve trust in your results and maintain the standard of rigorous, transparent science.*"
      },
      "placeholder": "Hypothesis 1: [State the first specific, testable hypothesis.]\n\nHypothesis 2: [State the second specific, testable hypothesis, distinct from H1.]\n\nWhy distinguishing these hypotheses matters:\n- \n- ",
      "llmInstructions": "Please review my hypothesis section. Do my hypotheses align with my research question? Are they distinct, specific and testable? Have I explained why distinguishing between them matters, and how my data will help decide between them? What improvements would you suggest?"
    },
  {
      "id": "theorysimulation",
      "title": "Theory/Simulation",
      "type": "text",
      "maxLength": 2500,
      "inputPlaceholder": "Describe your theoretical approach or simulation...",
      "instructions": {
        "title": "Theory/Simulation Approach",
        "text": "Theoretical models and simulations offer a way to explore systems, generate predictions, or test ideas when real-world experiments aren’t feasible. These approaches require clear assumptions, strong alignment with the question, and thoughtful validation. When well-executed, they can reveal insights beyond empirical data. \n\n **Align With Question: Show how your model or theory addresses your research question.** It should offer answers or explanations that match the kind of question you’re asking. *When you craft a theoretical or computational model, it needs to align with the essence of your inquiry—whether it’s exploring mechanisms or predicting outcomes. If your question is mechanistic, the model should detail causal pathways; if it’s predictive, it should generate testable forecasts. By tying your model explicitly to your question, you make it clear why your chosen approach is appropriate. This alignment helps advisors and readers see the direct relevance of your theoretical framework. It also justifies any simplifications or assumptions you make, showing they are strategically chosen to illuminate specific aspects of the phenomenon.* \n\n  **Key Assumptions: Clearly state the assumptions behind your model.** Justify why they are reasonable and how they relate to real systems. *All theories and simulations rely on assumptions—like linear relationships, idealized agents, or stable boundary conditions. Making these assumptions explicit reveals your model’s logical underpinnings and limitations. This transparency lets others judge how well your simplified representation might match actual phenomena. If your assumptions diverge substantially from the real world, the model’s predictions may be less applicable. Conversely, well-chosen assumptions can provide powerful insight by focusing on critical factors and filtering out noise. Stating them clearly helps critics or collaborators propose extensions or modifications to improve accuracy and comprehensiveness.* \n\n **Framework / Model: Describe your math, simulation, or algorithmic structure.** This is the engine of your theoretical work. *This section is the blueprint of your theoretical approach, showing exactly how components interact. Do you employ differential equations, agent-based modeling, or probabilistic networks? Outlining these elements makes your framework more accessible and reproducible. You’re also demonstrating your methodological grounding—whether you’re pulling from well-established theories or forging a new path. Clarity here also promotes peer feedback: others can suggest improvements, identify overlooked complexities, or highlight parallels to other fields. A robust, transparent model framework is what transforms your conceptual idea into a tangible, testable structure.* \n\n **Solution / Implementation: Explain how you’ll run the model or solve the equations.** Mention numerical methods, software, or custom tools you’ll use. *Even the most elegant theoretical construct can be stymied by practical hurdles if you lack an execution plan. Whether you’re coding a simulation in Python or using specialized solvers for your equations, detailing your toolset proves your approach is technically feasible. This step is especially crucial if you anticipate large computational demands or intricate debugging. If your approach involves approximations or iterative methods, specify how they converge or under which conditions they might fail. By being explicit, you set realistic expectations for performance and pave the way for others to replicate or validate your results.* \n\n  **Validation: Say how you will test if your theory matches reality.** Compare predictions to known results, data, or other models. *Theoretical models can diverge from empirical truths in unexpected ways, so validation is essential. You might compare your model’s outputs to real-world data, or benchmark them against simpler theoretical frameworks that have proven reliable. Documenting these validation checkpoints shows you’re not just working in isolation—rather, you’re continuously checking if your ideas align with evidence. If discrepancies arise, you can refine assumptions or incorporate additional factors. Demonstrating a clear validation plan assures others that your model isn’t purely abstract but has a credible claim to describing or predicting real phenomena.* \n\n  **Limitations & Contribution: Be transparent about weaknesses and how the theory still helps the field.** No model is perfect — explain what yours is good for and where it needs caution. *Honesty about your model’s boundaries increases trust. If you assume a homogenous population but real-world data suggests heterogeneity, note that your results may oversimplify group differences. Simultaneously, highlight where your theory pushes the conversation forward—maybe by capturing a previously neglected interaction or by introducing a novel computational approach. A balanced discussion of limitations and contributions lets readers appreciate the trade-offs you made. They’ll understand both the unique insights your model delivers and the conditions under which those insights might fall short, setting the stage for further refinement or collaborative development.*"
      },
      "placeholder": "Key Theoretical Assumptions:\n- \n- \n- \n\nRelationship to Real-world Phenomena:\n\nMathematical/Computational Framework:\n\nSolution/Simulation Approach:\n\nValidation Strategy:\n\nPotential Limitations:\n\nTheoretical Significance:"
    },
    {
      "id": "needsresearch",
      "title": "Needs-Based",
      "type": "text",
      "maxLength": 2000,
      "inputPlaceholder": "Define the needs your research addresses...",
      "instructions": {
        "title": "Needs-Based Research",
        "text": "Needs-based research starts from a real-world problem that someone experiences and builds the project around addressing it. This ensures your work is relevant and impactful for specific stakeholders. It also clarifies the value of your contribution beyond academia. \n\n **Alignment With Your Question: The research question should directly emerge from a practical need.** Your project should address a problem that someone experiences. That problem should be clearly visible in your question. *A needs-based approach grounds your research in real-world challenges, ensuring immediate relevance. If a concrete need underpins your question, it’s easier to show utility and attract interest from practitioners or stakeholders. This focus also guides your methods and measures—data collection can directly speak to practical concerns, making your findings more actionable. By placing the human or societal problem at the heart of your question, you orient your entire project toward solutions. The alignment between question and need is what differentiates pure academic curiosity from research with a tangible, problem-solving mission.* \n\n **Identify the Beneficiaries: Say exactly who benefits from solving this problem.**  Be specific — e.g., clinicians, patients with a condition, developers, policymakers. *Pinpointing beneficiaries makes your research human-centered. Whether it’s improving patient outcomes, easing a developer’s workload, or informing policy, clarity on whom you’re helping provides sharp direction. This specificity also shapes how you measure success: outcomes should matter to the identified group rather than just academic metrics. Moreover, naming the beneficiaries can guide partnerships and funding sources, as they’re more likely to support work that aligns with their mandates or interests. Ultimately, a needs-based project that explicitly states its target audience carries a more persuasive rationale and is more likely to gain momentum.* \n\n **Problem Statement: Clearly state what problem you are solving for them.** Frame the problem in terms of their experience, not just technical terms. *The problem statement lays out the pain point or gap that your research addresses, guiding the rest of your project’s design. By explaining the issue in the stakeholders’ language, you demonstrate empathy and ensure you focus on genuinely relevant solutions. Technical jargon can obscure the urgency or real-world impact, so a clear, user-oriented explanation resonates better. This approach also assists with scoping: if you can’t articulate the user’s challenge succinctly, you might need to refine or revisit your understanding. A strong problem statement is a beacon that keeps your entire project grounded in practical relevance.* \n\n **Current Solutions & Gaps: Explain what’s already available and why it isn’t enough.**  This sets up the value of your work and shows what’s missing. *By showcasing existing solutions, you illustrate the competitive landscape and underscore the need for innovation or improvement. This step is critical to avoid duplication of effort: you’re demonstrating that you know what’s out there and precisely where it falls short. Maybe the solutions are too expensive, inaccurate, or inaccessible to those who need them most. Pinpointing these deficiencies gives your project a clear raison d’être. It also helps potential collaborators or funders see how your work could close the gap, fostering interest and support. Demonstrating this awareness strengthens your credibility and can guide your own approach to building a better answer.* \n\n **Success Criteria: Say how you will know if your solution works.** Define metrics or benchmarks that matter to users, not just you. *A robust set of success metrics helps you gauge real-world effectiveness, not just theoretical outcomes. If your target group is clinicians, success might mean reduced procedure time or better patient recovery rates. For developers, success might hinge on fewer bugs or faster deployment. When these criteria are aligned with the experiences of actual users, your research gains authenticity and direct relevance. Moreover, defining these metrics early shapes your study design and data collection plans, ensuring you gather the evidence needed to evaluate whether you’ve truly addressed the problem as intended.* \n\n **Verify the Need: Try to confirm the problem is real and important.** Talk to stakeholders or cite evidence showing the need is recognized. *Nothing is more convincing than direct confirmation from the people facing the issue. Engaging stakeholders through interviews, surveys, or focus groups provides firsthand validation of your project’s importance. Alternatively, referencing official reports, academic literature, or usage data can also confirm that the need is significant and widespread. This step prevents you from “solving” a problem that doesn’t actually exist or is already well-resolved. Verification also safeguards your resources and time, channeling them into a line of investigation that truly addresses a recognized gap. Plus, credible evidence of need makes your argument far more compelling to peers and funders.*"
      },
      "placeholder": "Who needs this research:\n\nWhy they need it (specific problem to solve):\n\nCurrent approaches and their limitations:\n\nSuccess criteria (how will you measure if your solution works):\n\nAdvantages of your proposed approach:",
      "llmInstructions": "Please review my needs-based research section. Have I clearly identified the beneficiaries and their problem? Have I discussed current solutions and their limitations? Are my success criteria clear and relevant to users? What specific improvements would make this section stronger?"
    },
    {
      "id": "exploratoryresearch",
      "title": "Exploratory",
      "type": "text",
      "maxLength": 2000,
      "inputPlaceholder": "Define your exploratory approach...",
      "instructions": {
        "title": "Exploratory Research",
        "text": "Exploratory research allows you to investigate new datasets, behaviors, or systems without needing strong prior expectations. It helps generate hypotheses, identify patterns, and map out underexplored areas of interest. Despite its open-ended nature, it still requires clear framing and methodological rigor. \n\n **Alignment With Your Question: Even exploratory work should address a clearly stated question or curiosity.** You should know what you are exploring and why it might be worth it — even if you are not making predictions. *Exploratory research doesn’t require a rigid hypothesis, but it does need an overarching theme or focus. By setting a guiding question, you ensure that data collection and interpretation aren’t purely haphazard. This clarity also helps collaborators and advisors understand the purpose behind your exploration and provide meaningful input. Even if your end goal is simply to unearth patterns or gather preliminary insights, a loosely defined question keeps the project on track. Having this structure can lead to more coherent results that lay the foundation for future confirmatory studies.* \n\n **Phenomenon / Dataset: Describe what you’re exploring and why it’s interesting.** Mention why the dataset, behavior, or system is novel or unexplored. *When embarking on exploratory research, transparency about your starting point is key. Whether you’re dealing with an uncharted dataset or an understudied phenomenon, stating the novelty gives context to why you expect fresh insights. Maybe the dataset includes a unique population or merges multiple data sources in a way no one has done before. Alternatively, the phenomenon might be newly observed in the literature, offering a chance to break ground on an emerging topic. Explaining these unique elements not only justifies your work but also attracts interest from peers who might have overlapping questions or complementary expertise.* **Potential Patterns: List a few things you hope to find or investigate.**  You are not committing to finding them, just showing thoughtful anticipation. *Even when your goal is open-ended discovery, identifying potential patterns or relationships ahead of time helps shape your analysis plan. Perhaps you suspect certain variables correlate, or you want to see if clusters naturally emerge from the data. By articulating these possibilities, you approach the project with a sense of direction instead of aimless searching. It also helps you plan which analytical tools to deploy. If none of these patterns manifest, you still gain valuable knowledge. If they do, you’ve laid the groundwork for a more targeted follow-up study. This balance of openness and preliminary guidance enriches your exploratory work.* \n\n **Novelty and Value: Say why this exploration matters for your field.** What kind of research directions or insights might it open up? *Positioning your exploratory work in the context of the broader field highlights its relevance and potential impact. Maybe your findings could spur an entirely new research thread or guide the development of theoretical models that have yet to be tested. If the dataset or phenomenon is truly novel, your study might fill a key gap or inspire fresh collaborations. Explaining these possibilities shows that your exploration isn’t a random dive into data. It demonstrates strategic thinking that can lead to valuable contributions, even if the immediate outcome is simply mapping uncharted territory for others to build upon.* \n\n **Analytical Tools: Explain how you’ll analyze the data to find patterns.** Mention specific tools (e.g., clustering, factor analysis, visualization). *Selecting the right tools can make or break an exploratory study. Whether you choose clustering algorithms, dimensionality reduction, or advanced visualization techniques, each method should align with the nature of your data and your guiding questions. Summarizing these analytical approaches helps others understand your methodology and see how you plan to spot interesting patterns. Additionally, naming tools in advance signals a level of preparedness. You’re showing that you’re not just “hoping for something interesting” but have a strategy to sift through the data systematically. This thoughtful method selection also positions you to handle large or complex datasets more efficiently.* \n\n **Guarding Against Noise: Say how you’ll know if a pattern is real.** Reference strategies like cross-validation, expert review, or statistical tests. *Exploratory projects can easily stumble into spurious correlations or patterns driven by random variation. Explicitly stating how you’ll validate or check the robustness of any emerging patterns mitigates this risk. Cross-validation techniques, consultation with domain experts, or significance tests each provide different forms of evidence to confirm that what you’re seeing isn’t just noise. Declaring these strategies early on also keeps you honest, ensuring you don’t overinterpret convenient coincidences. Ultimately, building in mechanisms to guard against false positives enriches your exploration, making it more credible and beneficial for subsequent in-depth research.*"
      },
      "placeholder": "Phenomena/data/system to explore:\n\nPotential discoveries your approach might reveal:\n1. \n2. \n3. \n\nValue of this exploration to the field:\n\nAnalytical approaches for discovery:\n\nStrategy for validating findings:",
      "llmInstructions": "Please review my exploratory research approach. Have I clearly identified what I am exploring and why it is interesting? Have I outlined potential patterns I might find and why they matter? Are my analytical tools and validation strategies appropriate? What specific improvements would you suggest?"
    },
    {
      "id": "relatedpapers",
      "title": "Related Papers",
      "type": "text",
      "maxLength": 2000,
      "inputPlaceholder": "List the related papers here...",
      "instructions": {
        "title": "Identifying Relevant Literature",
        "text": "Understanding the existing literature is essential for situating your work within the scientific conversation. Reviewing key papers helps clarify what’s known, what’s missing, and how your project contributes. Engaging critically with both supporting and contrasting studies strengthens your framing and credibility. \n\n **Find Relevant Work: List at least 5 key papers related to your topic.** These should test similar hypotheses, use related methods, or target the same problem. *Identifying at least five cornerstone studies anchors your research in the existing knowledge base. Each paper should be chosen deliberately, serving as a critical point of comparison or a methodological foundation. This ensures you’re not working in a vacuum or reinventing the wheel. Importantly, it also allows others—committee members or peer reviewers—to see how well you’ve mapped the intellectual landscape. By systematically addressing these key papers, you highlight how your approach or question differs or complements prior work, demonstrating scholarly diligence.* \n\n **Connect to Each: For each, say how it relates to your own work.** Which part of your idea builds on it? Where do you differ? *This step cements your position in the scholarly conversation. Merely listing references doesn’t show depth of engagement; explaining the links does. If a paper outlines a relevant experiment, note how you’ll replicate or modify its protocol. If another offers a competing theory, clarify which elements you adopt or challenge. This contextual mapping reveals how your research emerges from, disputes, or extends established findings. By articulating these intersections clearly, you offer a roadmap for how your project builds on past successes—or addresses persistent gaps and inconsistencies.* \n\n  **Identify the Gap: Say what your project does that they didn’t.**This is the core reason your project matters. If your study is a replication study, make sure you mention that. *Pinpointing an unresolved question or neglected angle illuminates the uniqueness of your contribution. Maybe prior papers used small sample sizes or overlooked a particular demographic. Possibly they established correlation but never explored causation. Whatever the shortcoming, placing it front and center shows reviewers and readers exactly why your study is needed. If it’s a replication, emphasize what sets yours apart—perhaps a more diverse population or updated tools. This clarity about the gap guarantees your work isn’t just an incremental addition but a meaningful step forward in the academic dialogue.* \n\n **Consider Contrasts: Include at least one paper that disagrees or takes a different view.** This sharpens your thinking and strengthens your framing. *Engaging with dissenting or contrasting perspectives prevents intellectual echo chambers. By wrestling with studies that conflict with your hypothesis or methodology, you improve your own rigor. You’ll have a deeper understanding of alternative explanations, which can help you plan more robust tests or interpret unexpected results. Including contrary evidence also demonstrates integrity and depth, signaling that you’re not afraid to confront challenges to your viewpoint. This willingness to engage with differing opinions often leads to more nuanced conclusions and can spark creative ways to reconcile or test conflicting findings.* \n\n  **Search Strategy: Explain how you searched for literature and how you will handle conflicting findings.** Mention databases, keywords, and what you will do if the literature is split. *Detailing your search process—like which academic databases or relevant search terms you used—offers transparency and reproducibility. It shows that you didn’t cherry-pick papers to fit a narrative. If your exploration turns up conflicting evidence, clarify whether you’ll weigh methodological quality, sample sizes, or consensus across multiple studies. This approach frames you as an even-handed investigator open to multiple interpretations. By laying out how you handle discrepancies, you minimize bias and demonstrate readiness to adapt your hypotheses or methods should the literature point in a new direction.* "
      },
      "placeholder": "Most similar papers that test related hypotheses:\n1. \n2. \n3. \n4. \n5. ",
      "llmInstructions": "Please review my related papers section. Have I included at least 5 key papers, explained how each relates to my work, identified the gap my project fills, and included contrasting perspectives? What specific improvements would make this section stronger?"
    },
    {
      "id": "experiment",
      "title": "Experiment",
      "type": "text",
      "maxLength": 2500,
      "inputPlaceholder": "Start designing your experiment here...",
      "instructions": {
        "title": "Experiment",
        "text": "Designing a new experiment is a chance to generate novel data and test your hypotheses directly. A good experimental plan ensures your methods align with your question, controls for confounds, and anticipates the results you will use to draw conclusions. Clarity here boosts validity and reproducibility. \n\n **Align With Question: The experiment must directly address your research question. ** Make sure you are measuring what you need to answer the question or test the hypothesis. *Every aspect of your experimental design—participants, tasks, measurements, and controls—should relate back to your central research question. This alignment keeps you from gathering extraneous data that doesn’t move the project forward or, worse, omitting crucial data that does. Reviewers look for coherence: a direct, unbroken line from question to design to analysis. By emphasizing how each variable ties to your question, you reassure others that your study is well-conceived. Moreover, this clarity simplifies data interpretation later, as you’ll know exactly which outcomes speak to your core objectives.* \n\n **Variables & Sampling: Define your variables and your sample.** Be clear about what you are manipulating, measuring, and controlling. *Clear definitions reduce ambiguity and allow others to replicate your methodology. The independent variable(s) (what you change) and dependent variable(s) (what you measure) frame how you’ll infer cause-and-effect—or at least correlations. Controls limit extraneous factors that could muddy interpretations. Meanwhile, sampling decisions—who or what you study—determine how generalizable your conclusions can be. Make sure to outline demographic details (e.g., age, profession, relevant experience) or other sample characteristics relevant to your field. This transparency ensures your study’s scope and boundary conditions are understood, setting realistic expectations for how broadly findings can be applied.* \n\n **Data Collection: Describe your procedures clearly and completely.** Explain tasks, timelines, equipment, and any controls or randomization. *Laying out the full procedural timeline helps others grasp each step participants take or each stage of data generation. If you’re using special equipment, detail the make, model, and calibration settings where relevant. For experiments involving human participants, specify instructions they’ll receive, randomization schemes, or environmental conditions (like temperature or noise levels). Such thoroughness supports replicability and demonstrates good scientific practice. It also reduces confusion over whether extraneous factors might have influenced your results. If your methods are novel, the clarity of your protocol description can be particularly valuable to peers who want to adopt or critique your approach.* \n\n **Predicted Results:If testing hypotheses, say what you expect under each.** Helps make your logic transparent and testable. *You can’t always predict specific numeric outcomes, but you can anticipate patterns, trends, or significant relationships. If you have multiple hypotheses, articulate how each might manifest in your results—for instance, a difference between experimental and control groups, or a correlation within a certain threshold. This transparency signals that you’ve pre-committed to certain interpretations, reducing the temptation to retrofit explanations later. It also helps you design appropriate statistical analyses in advance. And if the data diverge from your predictions, you’ll know immediately that something new or unexpected is at play.* \n\n **Confounds & Controls: Identify possible confounds and how you’ll reduce them.** This improves your design and increases confidence in your results. *Confounds are lurking variables that could explain your findings instead of—or in addition to—your main variables of interest. Acknowledging them early shows that you’ve critically evaluated your design. You might control these confounds by random assignment, matching participants on certain characteristics, or standardizing conditions. This proactive step tightens the causal argument (if your study is structured to support one) or clarifies correlation strength. Explicitly listing potential confounds also encourages scrutiny from advisors or committee members, who may spot additional issues. Addressing these concerns before data collection can prevent major headaches down the line.* \n\n **Blinding and Masking: Whenever humans are involved they will be biased if they know too much.** It helps protect against unconscious bias and supports transparency. *Blinding—whether single, double, or triple—shields participants and/or experimenters from details that could skew the results. This might mean hiding group assignments or the specific hypothesis being tested. Even well-intentioned researchers can unconsciously influence outcomes if they know what they’re “supposed” to find. Implementing blinding reduces this risk, making outcomes more credible. In many fields, a double-blind design is considered gold standard because it guards against biases from both participants and experimenters. By planning blinding upfront, you show a commitment to objectivity that bolsters the entire study’s trustworthiness.* \n\n **Preregistration: Consider preregistering your plan.** It helps further protect against unconscious bias and supports transparency. *Preregistration means documenting your hypotheses, methods, and analysis plan before you start collecting data. Doing so can be as simple as writing a timestamped document or using an online registry. This practice counters the temptation to tweak hypotheses retroactively based on surprising results. By specifying your approach in advance, you reinforce the integrity of your study and make it simpler for others to follow your reasoning. Preregistration also opens doors for more rigorous meta-analyses in the future, as it clarifies the difference between planned tests and exploratory analyses in published work.*"
      },
      "placeholder": "Key Variables:\n- Independent: \n- Dependent: \n- Controlled: \n\nSample & Size Justification: \n\nData Collection Methods: \n\nPredicted Results: \n\nPotential Confounds & Mitigations:",
      "llmInstructions": "Please review my experimental design. Does it clearly align with my research question? Have I properly defined variables, sampling, procedures, and predicted results? Have I addressed potential confounds and considered blinding where appropriate? What specific improvements would you suggest?"
    },
    {
      "id": "existingdata",
      "title": "Acquiring Pre-existing Data",
      "type": "text",
      "maxLength": 2500,
      "inputPlaceholder": "Describe the pre-existing data you plan to use...",
      "instructions": {
        "title": "Using Pre-existing Datasets",
        "text": "Using existing datasets can save time and resources, but requires careful evaluation. It’s important to confirm that the dataset fits your question, has adequate quality, and was collected ethically. A good fit between data and question supports strong, interpretable conclusions. \n\n **Align With Question: Confirm the dataset fits your question and contains the key variables you need.** Don’t shoehorn an unrelated dataset into your question — or revise your question just to match a dataset. *Leveraging an existing dataset can be cost-effective but only if it genuinely aligns with your research goals. For instance, if you need longitudinal behavioral measures but the dataset only offers cross-sectional snapshots, that mismatch will compromise your ability to answer the question. Ensuring a tight fit prevents wasted effort on partial or unsuitable data that can’t produce the insights you need. This alignment also spares you from contorting your question into something it wasn’t meant to be. Double-check that the necessary variables, time spans, and metadata are all present and consistent with your original aims before diving into analysis.* \n\n **Source & Provenance: Say who collected the data and for what purpose.** This helps reveal potential biases or gaps. *Understanding the data’s origin story clarifies how it was gathered and any implicit assumptions in its structure. For instance, if a government agency collected it, there might be bureaucratic constraints or policy-driven sampling strategies that affect representativeness. If it comes from a private company, business interests could have shaped the variables tracked. Acknowledging these influences guides interpretation. It also flags potential biases—such as systematically missing certain demographics or using outdated measures. Documenting provenance is an ethical and practical necessity, signaling transparency to peers who might later want to replicate or expand upon your work.* \n\n **Access & Permissions: Confirm you can legally and ethically use the data.** Mention licensing, IRB approval, or data agreements as needed. *Data usage can involve strict regulations, especially if it includes personal or sensitive information. By clarifying that you have the right approvals—whether from institutional review boards, data providers, or licensing authorities—you protect both participants’ rights and your own research credibility. This section helps you avoid legal complications and ensures that your dissertation or publications won’t be retracted for unauthorized data use. Detailing how you acquired the dataset, any relevant contracts, or anonymization processes also builds trust with collaborators and reviewers, who want to see that your methods uphold best practices for privacy and compliance.* \n\n **Data Quality: Assess whether the data is reliable and usable for your purpose.** Mention missing data, measurement noise, or known problems. *Existing data sets often come with “warts” like incomplete entries, variable coding errors, or outdated collection methods. A thorough quality check can include screening for outliers, analyzing missingness patterns, and verifying measurement scales. By documenting these findings, you indicate whether extensive cleaning or transformations are required before robust analysis can begin. This honesty also tempers expectations about the strength and scope of your results. If the dataset isn’t pristine, you can still proceed, but you must explain how you’ll address limitations. Transparency about data quality fosters confidence in your eventual interpretations and conclusions.* \n\n **Limitations of Reuse: Acknowledge downsides of using someone else’s data.** Be honest about tradeoffs in fit, flexibility, or generalizability. *While reusing existing data is efficient, there are inherent limitations. You can’t typically revise the collection protocol if you uncover gaps, and certain key variables might be absent. The sample may not represent the population you care about most. These constraints can impact internal or external validity. Being upfront about these issues allows readers to weigh your findings appropriately and reduces the chance that you’ll overclaim. Despite these tradeoffs, well-documented secondary data can still offer meaningful insights—just be sure you’re transparent about where it falls short and how that might affect your interpretations.*"
      },
      "placeholder": "Dataset name and source: \n- Original purpose of data collection: \n- Rights/permissions to use the data: \n-Data provenance and quality information: \n- Relevant variables in the dataset: \n- Potential limitations of using this dataset:",
      "llmInstructions": "Please review my plan for using pre-existing data. Does the dataset clearly fit my question? Have I addressed its source, quality, and ethical considerations? Have I been honest about limitations? What specific improvements would make this section stronger?"
    },
    {
      "id": "analysis",
      "title": "Data Analysis",
      "type": "text",
      "maxLength": 3000,
      "inputPlaceholder": "Start planning your data analysis here...",
      "instructions": {
        "title": "Data Analysis Plan",
        "text": "Data analysis is how you turn raw information into meaningful findings. A clear plan ensures your analyses are rigorous, appropriate for your hypotheses, and transparent about uncertainty and limitations. Good analysis connects directly back to your research question and strengthens your conclusions. \n\n **Cleaning & Exclusion: Define how you will process raw data and exclude cases.** Mention thresholds for outliers, missing values, or noisy measurements. *Raw data often contains errors, extreme values, or gaps that can skew results. Documenting your cleaning process ensures you won’t inadvertently bias analyses by selectively discarding data. Perhaps you’ll exclude participants who didn’t complete key tasks or remove sensor readings that exceed a certain noise threshold. Specify these rules ahead of time to maintain transparency. By noting details like missing-data imputation methods or outlier cutoffs, you help others replicate your study precisely. Thorough documentation also boosts confidence in your findings by showing you’ve carefully managed messy real-world inputs.* \n\n **Statistical Methods: Specify your main analysis tools and why they’re appropriate.** Connect to your research question and hypotheses. *The statistical or computational techniques you choose should be guided by the type of data and your central research aims. Are you using regression for predictive insights, a t-test for group comparisons, or a Bayesian framework for probabilistic modeling? Explaining this rationale helps readers grasp how you’ll test each hypothesis and interpret results. It also preempts criticisms that you applied the wrong tool for the job. By clearly linking your methods to your research question, you demonstrate a coherent plan that stands up to scrutiny, increases validity, and makes your results more compelling.* \n\n **Uncertainty & Robustness: Say how you will quantify and test uncertainty.** Think confidence intervals, resampling, sensitivity analysis. *Acknowledging uncertainty is a mark of scientific rigor. Beyond reporting p-values, you might include confidence or credible intervals, run simulations to see how results vary if assumptions change, or perform sensitivity analyses that test alternative parameter settings. These approaches help you and your audience understand how stable your findings are under different conditions. If your result is highly sensitive to slight tweaks in the data or model, that signals the need for caution in drawing broad conclusions. Embracing and detailing these techniques upfront ensures you’re neither overstating the certainty of your outcomes nor ignoring potential data weaknesses.* \n\n **Multiple Comparisons & Effect Sizes: Control false positives and show practical relevance.** Use FDR, Bonferroni, and always report effect sizes if possible. *When you perform numerous tests, the chance of finding a statistically significant but meaningless effect rises. Implementing corrections like Bonferroni or FDR shows that you’re serious about controlling Type I errors. Additionally, effect sizes offer a more intuitive sense of impact: even if a result is statistically significant, it might be negligible in real-world contexts. By reporting both p-values and effect sizes, you strike a balance between statistical rigor and practical relevance. This dual reporting aligns your findings with emerging best practices and enhances the transparency and validity of your conclusions.* \n\n **Planned vs Exploratory: Clearly separate confirmatory and exploratory work.** Label things that weren’t in your original plan so you don’t accidentally overclaim. *Distinguishing between pre-registered analyses and post hoc discoveries is vital for credibility. Confirmatory analyses test your predefined hypotheses, while exploratory ones can unearth unexpected relationships. By labeling them as such, you maintain honesty about how your findings emerged and avoid inadvertently inflating their significance. This clarity also helps other researchers understand which results deserve replication or further scrutiny. Ultimately, preserving a clear boundary between the planned and the exploratory fosters more robust, replicable research, and encourages healthy scientific curiosity without compromising methodological transparency.* \n\n **Answering the Question: Show how your analysis directly supports your question and hypotheses.** Make the link between data and logic as tight and transparent as possible. *Your analytical plan should be a logical extension of the research question, closing the loop from hypotheses to measurable outcomes. If your question is about group differences, ensure your analysis highlights comparisons. If it’s about relationships, set up correlation or regression frameworks. Then interpret findings in a way that directly addresses the question. This cohesion helps readers see the thread running through every stage of your project. It also prevents you from drifting into tangential interpretations. When data analysis stays laser-focused on your original goals, your conclusions become more convincing and coherent.*"
      },
      "placeholder": "Data Cleaning & Exclusions:\n\nPrimary Analysis Method:\n\nHow Analysis Addresses Research Question:\n\nUncertainty Quantification:\n\nSpecial Cases Handling:",
      "llmInstructions": "Please review my data analysis plan. Have I clearly outlined my data cleaning procedures, statistical methods, and approaches to uncertainty? Have I addressed multiple comparisons and distinguished between planned and exploratory analyses? Does my analysis directly connect to my research question? What improvements would you suggest?"
    },
    {
      "id": "process",
      "title": "Process",
      "type": "text",
      "maxLength": 3000,
      "inputPlaceholder": "Outline your process, skills, and timeline...",
      "instructions": {
        "title": "Research Process",
        "text": "Behind every good project is a good process. This includes planning your timeline, identifying collaborators, managing your data/code, and preparing for risks. Good process ensures smoother execution and helps you stay organized, transparent, and resilient throughout your projects. \n\n **Skills Inventory: List needed skills and what you’ll do if you lack some.** Include technical, analytic, and communication skills. *Every project demands a variety of competencies—maybe advanced programming, specialized statistical approaches, or strong writing for literature reviews. By charting out these requirements from the start, you can tackle learning curves proactively. If you realize a gap in expertise, you might take a relevant workshop, seek a mentor, or invite a collaborator who has that skill. This foresight helps you allocate time and resources effectively, reducing stressful surprises mid-project. Plus, reflecting on your skill set reminds you to cultivate professional growth alongside accomplishing research milestones.* \n\n **Collaboration Plan: Identify key collaborators and their roles.** Clarify contributions and what they bring to the project. *Collaboration fuels faster progress, deeper insights, and valuable cross-disciplinary exchanges. Defining who does what upfront avoids confusion or duplication of effort later. Specify if someone will lead data collection, another will handle statistical modeling, and a third will oversee lab management. Clarify any authorship expectations or intellectual property agreements as well. When roles are transparent, everyone can play to their strengths, and the project’s workflow becomes more efficient. It also helps with accountability—knowing each person’s responsibilities encourages timeliness and higher-quality work across the entire research team.* \n\n **Data/Code Management: Plan how you’ll share and document your work.** Use version control and consider open-access tools when possible. *Good data and code management ensures your research remains reproducible and transparent. By using version control systems like Git, you prevent confusion about file versions or overwriting vital scripts. Consistent file naming and directory structures help future you—and any collaborators—quickly locate and understand materials. Consider public repositories for open science if ethics and permissions allow, expanding your project’s visibility. Proper documentation, such as READMEs or inline comments, clarifies workflows and fosters collaboration. Ultimately, a solid management plan not only aids your own efficiency but also amplifies your research’s reach and credibility.* \n\n **Timeline & Milestones: Lay out a feasible schedule with deliverables.** Helps you stay on track and catch delays early. Most projects take twice as long than planned. Recursively. *Projects can sprawl, so breaking them into defined tasks with deadlines is essential. Outline major phases—like literature review, data collection, analysis, and writing—then set specific goals and checkpoints for each. This structure provides a roadmap to gauge progress and adjust if unexpected delays arise. Hitting (or missing) milestones gives valuable feedback on whether your scope is realistic. It also keeps collaborators informed, enabling them to schedule their contributions effectively. A well-thought-out timeline promotes accountability, motivation, and a clearer sense of how all the pieces fit together toward dissertation completion.* \n\n **Risk Planning: Identify major risks and fallback strategies.** Anticipate what could go wrong and how you’ll adapt. *Risk is unavoidable in research: equipment might fail, data collection could stall, or pilot results may reveal design flaws. By proactively listing these vulnerabilities, you give yourself the opportunity to create contingency plans—alternative datasets, revised protocols, or extra buffer time. This forward thinking reduces the chance of being blindsided and helps maintain momentum when things don’t go perfectly. It also demonstrates maturity and preparedness to advisors or committee members, who appreciate seeing that you’re not taking success for granted. A thorough risk assessment ensures that inevitable roadblocks won’t derail your entire project.* \n\n **Open Science: Adopt open practices where possible and clarify constraints.** This builds trust and increases the impact of your work. *Open science encompasses sharing data, code, and sometimes even preliminary analyses or registrations. Adopting these practices fosters transparency and collaboration, enabling other researchers to replicate or extend your work. However, not all data can be freely shared—confidentiality, security, or proprietary concerns might limit full openness. Be upfront about these constraints so readers understand why certain materials remain private. Embracing open science where feasible can lead to broader recognition, more citations, and stronger community support. Ultimately, it signals your commitment to rigorous and ethical research.*"
      },
      "placeholder": "Skills Needed vs. Skills I Have:\n\nCollaborators & Their Roles:\n\nData/Code Sharing Plan:\n\nTimeline & Milestones:\n\nObstacles & Contingencies:",
      "llmInstructions": "Please review my process plan. Have I realistically assessed the skills needed and how to address any gaps? Have I identified collaborators and their roles? Is my timeline realistic with clear milestones? Have I addressed potential risks and open science practices? What specific improvements would strengthen this section?"
    },
    {
      "id": "abstract",
      "title": "Abstract",
      "type": "text",
      "maxLength": 1500,
      "inputPlaceholder": "Draft your abstract here...",
      "instructions": {
        "title": "Drafting an Abstract",
        "text": "The abstract is the first—and sometimes only—part of your work that others will read. It should clearly summarize your question, methods, expected results, and significance in a concise, accessible way. A strong abstract draws in your audience and highlights the value of your work. \n\n**Background: Introduce the area and the problem/gap.** Keep it short. Assume the reader knows the general field but not the specific issue. *The background in your abstract provides a quick context to orient readers. You don’t need to regurgitate everything—just enough to highlight the specific gap or problem your study addresses. A concise, well-crafted background primes your audience to appreciate what follows in the objective, methods, and results. It also signals why your topic matters. By focusing on the crucial points only, you keep the abstract streamlined and prevent losing people who are skimming for relevance. Done right, a succinct background ensures your work stands out in a sea of scholarly papers.* \n\n **Objective / Question: State the question, hypothesis, or problem.** This is your one-sentence North Star. *Placing your research question front and center in the abstract is key. It immediately tells readers what issue you’re tackling—providing a strong anchor they can refer back to as they read on. This one-sentence statement should encapsulate the main thrust of your entire project. Ambiguity in the abstract can confuse or disinterest potential readers, so brevity and directness matter. A crisp objective or question also helps you maintain a coherent focus, ensuring that the rest of the abstract (and paper) consistently ties back to this guiding beacon.* \n\n **Methods: Summarize how you’ll answer the question.** Include key techniques, datasets, or models — briefly. *This section should be a bite-sized overview of your research approach, not a full protocol. If you’re running a double-blind experiment, say so. If you’re analyzing a large public dataset, mention that. If you’re building a computational model, name the main algorithmic techniques. Readers want just enough detail to gauge validity and relevance. By highlighting your core methods, you convey the rigor behind your work without bogging down the abstract with procedural minutiae. It reassures other researchers that you’ve used appropriate tools to tackle your stated question.* \n\n **Expected Results: Say what kind of outcome you expect or hope for.** This helps readers understand what success would look like. *Outlining the anticipated findings gives readers a roadmap of where your study is heading. You don’t need to overpromise or provide exact figures—just a ballpark of the trends or relationships you predict. This might be as broad as we expect to observe a significant improvement in performance measures or “we anticipate identifying new behavioral clusters.” This step also clarifies the scope of your work. If reality contradicts these expectations, that could be equally enlightening, but at least you’ve demonstrated a clear hypothesis or objective up front.* \n\n **Conclusion / Implications: State the main expected impact.** What should your reader believe, do, or study next after reading your paper? *Wrapping up your abstract with a concise statement of why your study matters leaves a strong impression. Maybe your findings can reshape a clinical protocol, spark an entirely new research direction, or confirm a theoretical stance. By articulating these implications clearly, you encourage readers to think about how they can apply or extend your work. It also frames your study’s contribution within the broader scholarly or practical landscape. An impactful conclusion often helps your paper stand out, signaling that your research is more than an isolated investigation—it has tangible takeaways for the field and beyond.*"
      },
      "placeholder": "Background: [simple description based on text]\n\nObjective/Question: [simple description based on text]\n\nMethods: [simple description based on text]\n\n(Expected) Results: [simple description based on text]\n\nConclusion/Implications: [simple description based on text]",
      "llmInstructions": "Please review my abstract. Does it concisely cover background, objective, methods, expected results, and implications? Is it clear, accessible, and compelling? What specific improvements would make this abstract more effective at drawing in readers and communicating the value of my work?"
    }
  ]
}
